{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will show a very simple classification using Logistic Regression. My goal here is to determine based on stats whether the player is defenseman of forward. As a NHL enthusiast I'm using NHL dataset from season 2016-2017. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'MLmetrics' was built under R version 3.4.4\"\n",
      "Attaching package: 'MLmetrics'\n",
      "\n",
      "The following object is masked from 'package:base':\n",
      "\n",
      "    Recall\n",
      "\n",
      "Warning message:\n",
      "\"package 'caTools' was built under R version 3.4.4\""
     ]
    }
   ],
   "source": [
    "#Lets read in packages I'm going to use in this notebook. If you don't have them, install them using command for example:\n",
    "# install.packages('Amelia') and remember to use quotes\n",
    "\n",
    "library(readxl)\n",
    "library(dplyr)\n",
    "library(MLmetrics)\n",
    "library(caTools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Born</th><th scope=col>City</th><th scope=col>Pr/St</th><th scope=col>Cntry</th><th scope=col>Nat</th><th scope=col>Ht</th><th scope=col>Wt</th><th scope=col>DftYr</th><th scope=col>DftRd</th><th scope=col>Ovrl</th><th scope=col>...</th><th scope=col>1st</th><th scope=col>2nd</th><th scope=col>3rd</th><th scope=col>MGL</th><th scope=col>Injuries</th><th scope=col>CHIP</th><th scope=col>NMC</th><th scope=col>Status</th><th scope=col>Salary</th><th scope=col>Cap Hit</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1988-04-30            </td><td>Hamilton              </td><td>ON                    </td><td>CAN                   </td><td>CAN                   </td><td>69                    </td><td>170                   </td><td>NA                    </td><td>NA                    </td><td>NA                    </td><td>...                   </td><td>NA                    </td><td>NA                    </td><td>NA                    </td><td>NA                    </td><td>NA                    </td><td>NA                    </td><td>NA                    </td><td>UFA                   </td><td>575000                </td><td>575000                </td></tr>\n",
       "\t<tr><td>1987-02-25            </td><td>Muskegon              </td><td>MI                    </td><td>USA                   </td><td>USA                   </td><td>74                    </td><td>218                   </td><td>2005                  </td><td>2                     </td><td>42                    </td><td>...                   </td><td>0                     </td><td>0                     </td><td>1                     </td><td>18                    </td><td>Lower body, Knee      </td><td>932927                </td><td>NTC                   </td><td>UFA                   </td><td>5500000               </td><td>4250000               </td></tr>\n",
       "\t<tr><td>1993-09-23            </td><td>Stockholm             </td><td>NA                    </td><td>SWE                   </td><td>SWE                   </td><td>71                    </td><td>196                   </td><td>2012                  </td><td>2                     </td><td>37                    </td><td>...                   </td><td>0                     </td><td>0                     </td><td>1                     </td><td>NA                    </td><td>NA                    </td><td>NA                    </td><td>NA                    </td><td>RFA                   </td><td>842500                </td><td>780833                </td></tr>\n",
       "\t<tr><td>1991-12-01            </td><td>Johnston              </td><td>RI                    </td><td>USA                   </td><td>USA                   </td><td>70                    </td><td>208                   </td><td>NA                    </td><td>NA                    </td><td>NA                    </td><td>...                   </td><td>0                     </td><td>0                     </td><td>1                     </td><td>15                    </td><td>Lower body, Upper body</td><td>144970                </td><td>NA                    </td><td>RFA                   </td><td>892500                </td><td>792500                </td></tr>\n",
       "\t<tr><td>1992-04-30            </td><td>Morristown            </td><td>NJ                    </td><td>USA                   </td><td>USA                   </td><td>72                    </td><td>202                   </td><td>2010                  </td><td>5                     </td><td>140                   </td><td>...                   </td><td>0                     </td><td>1                     </td><td>0                     </td><td>NA                    </td><td>NA                    </td><td>NA                    </td><td>NA                    </td><td>UFA                   </td><td>625000                </td><td>625000                </td></tr>\n",
       "\t<tr><td>1997-07-26            </td><td>Rauma                 </td><td>NA                    </td><td>FIN                   </td><td>FIN                   </td><td>71                    </td><td>172                   </td><td>2015                  </td><td>2                     </td><td>35                    </td><td>...                   </td><td>5                     </td><td>1                     </td><td>4                     </td><td>NA                    </td><td>NA                    </td><td>NA                    </td><td>NA                    </td><td>RFA                   </td><td>925000                </td><td>925000                </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       " Born & City & Pr/St & Cntry & Nat & Ht & Wt & DftYr & DftRd & Ovrl & ... & 1st & 2nd & 3rd & MGL & Injuries & CHIP & NMC & Status & Salary & Cap Hit\\\\\n",
       "\\hline\n",
       "\t 1988-04-30             & Hamilton               & ON                     & CAN                    & CAN                    & 69                     & 170                    & NA                     & NA                     & NA                     & ...                    & NA                     & NA                     & NA                     & NA                     & NA                     & NA                     & NA                     & UFA                    & 575000                 & 575000                \\\\\n",
       "\t 1987-02-25             & Muskegon               & MI                     & USA                    & USA                    & 74                     & 218                    & 2005                   & 2                      & 42                     & ...                    & 0                      & 0                      & 1                      & 18                     & Lower body, Knee       & 932927                 & NTC                    & UFA                    & 5500000                & 4250000               \\\\\n",
       "\t 1993-09-23             & Stockholm              & NA                     & SWE                    & SWE                    & 71                     & 196                    & 2012                   & 2                      & 37                     & ...                    & 0                      & 0                      & 1                      & NA                     & NA                     & NA                     & NA                     & RFA                    & 842500                 & 780833                \\\\\n",
       "\t 1991-12-01             & Johnston               & RI                     & USA                    & USA                    & 70                     & 208                    & NA                     & NA                     & NA                     & ...                    & 0                      & 0                      & 1                      & 15                     & Lower body, Upper body & 144970                 & NA                     & RFA                    & 892500                 & 792500                \\\\\n",
       "\t 1992-04-30             & Morristown             & NJ                     & USA                    & USA                    & 72                     & 202                    & 2010                   & 5                      & 140                    & ...                    & 0                      & 1                      & 0                      & NA                     & NA                     & NA                     & NA                     & UFA                    & 625000                 & 625000                \\\\\n",
       "\t 1997-07-26             & Rauma                  & NA                     & FIN                    & FIN                    & 71                     & 172                    & 2015                   & 2                      & 35                     & ...                    & 5                      & 1                      & 4                      & NA                     & NA                     & NA                     & NA                     & RFA                    & 925000                 & 925000                \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Born | City | Pr/St | Cntry | Nat | Ht | Wt | DftYr | DftRd | Ovrl | ... | 1st | 2nd | 3rd | MGL | Injuries | CHIP | NMC | Status | Salary | Cap Hit | \n",
       "|---|---|---|---|---|---|\n",
       "| 1988-04-30             | Hamilton               | ON                     | CAN                    | CAN                    | 69                     | 170                    | NA                     | NA                     | NA                     | ...                    | NA                     | NA                     | NA                     | NA                     | NA                     | NA                     | NA                     | UFA                    | 575000                 | 575000                 | \n",
       "| 1987-02-25             | Muskegon               | MI                     | USA                    | USA                    | 74                     | 218                    | 2005                   | 2                      | 42                     | ...                    | 0                      | 0                      | 1                      | 18                     | Lower body, Knee       | 932927                 | NTC                    | UFA                    | 5500000                | 4250000                | \n",
       "| 1993-09-23             | Stockholm              | NA                     | SWE                    | SWE                    | 71                     | 196                    | 2012                   | 2                      | 37                     | ...                    | 0                      | 0                      | 1                      | NA                     | NA                     | NA                     | NA                     | RFA                    | 842500                 | 780833                 | \n",
       "| 1991-12-01             | Johnston               | RI                     | USA                    | USA                    | 70                     | 208                    | NA                     | NA                     | NA                     | ...                    | 0                      | 0                      | 1                      | 15                     | Lower body, Upper body | 144970                 | NA                     | RFA                    | 892500                 | 792500                 | \n",
       "| 1992-04-30             | Morristown             | NJ                     | USA                    | USA                    | 72                     | 202                    | 2010                   | 5                      | 140                    | ...                    | 0                      | 1                      | 0                      | NA                     | NA                     | NA                     | NA                     | UFA                    | 625000                 | 625000                 | \n",
       "| 1997-07-26             | Rauma                  | NA                     | FIN                    | FIN                    | 71                     | 172                    | 2015                   | 2                      | 35                     | ...                    | 5                      | 1                      | 4                      | NA                     | NA                     | NA                     | NA                     | RFA                    | 925000                 | 925000                 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  Born       City       Pr/St Cntry Nat Ht Wt  DftYr DftRd Ovrl ... 1st 2nd 3rd\n",
       "1 1988-04-30 Hamilton   ON    CAN   CAN 69 170 NA    NA    NA   ... NA  NA  NA \n",
       "2 1987-02-25 Muskegon   MI    USA   USA 74 218 2005  2     42   ... 0   0   1  \n",
       "3 1993-09-23 Stockholm  NA    SWE   SWE 71 196 2012  2     37   ... 0   0   1  \n",
       "4 1991-12-01 Johnston   RI    USA   USA 70 208 NA    NA    NA   ... 0   0   1  \n",
       "5 1992-04-30 Morristown NJ    USA   USA 72 202 2010  5     140  ... 0   1   0  \n",
       "6 1997-07-26 Rauma      NA    FIN   FIN 71 172 2015  2     35   ... 5   1   4  \n",
       "  MGL Injuries               CHIP   NMC Status Salary  Cap Hit\n",
       "1 NA  NA                     NA     NA  UFA    575000  575000 \n",
       "2 18  Lower body, Knee       932927 NTC UFA    5500000 4250000\n",
       "3 NA  NA                     NA     NA  RFA    842500  780833 \n",
       "4 15  Lower body, Upper body 144970 NA  RFA    892500  792500 \n",
       "5 NA  NA                     NA     NA  UFA    625000  625000 \n",
       "6 NA  NA                     NA     NA  RFA    925000  925000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lets read in the data\n",
    "NHL_16_17 <- read_excel(\"NHL_16_17.xls\")\n",
    "nhl <- NHL_16_17[2:890,]\n",
    "colnames(nhl) <- nhl[1,]\n",
    "nhl <- nhl[2:889,]\n",
    "head(nhl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see that we have many different columns such as Nationality, Height, Weight and Country. But in this case I'm narrowing down columns to five possible candidates: points, time on ice per game, position, penalty minutes and shifts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nhl$Points <- as.numeric(nhl$PTS)\n",
    "points <- nhl$Points\n",
    "nhl$TimeOnIce <- nhl$`TOI/GP`\n",
    "nhl$TimeOnIce <- as.numeric(unlist(nhl$TimeOnIce))\n",
    "timeOnIce <- nhl$TimeOnIce\n",
    "nhl$Position <- as.factor(nhl$Position)\n",
    "position <- nhl$Position\n",
    "penalty_mins <- as.numeric(nhl$PIM)\n",
    "shifts <- as.numeric(nhl$Shifts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I will combine these vector in order to create data matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>points</th><th scope=col>timeOnIce</th><th scope=col>penalty_mins</th><th scope=col>shifts</th><th scope=col>position</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 0      </td><td> 8.56667</td><td> 0      </td><td>  12    </td><td>LW      </td></tr>\n",
       "\t<tr><td>21      </td><td>16.65000</td><td>50      </td><td>1397    </td><td>LW/RW   </td></tr>\n",
       "\t<tr><td> 2      </td><td>12.33330</td><td> 4      </td><td> 256    </td><td>LW      </td></tr>\n",
       "\t<tr><td> 5      </td><td>10.23330</td><td>16      </td><td> 431    </td><td>C       </td></tr>\n",
       "\t<tr><td> 3      </td><td>12.78330</td><td> 2      </td><td> 117    </td><td>LW      </td></tr>\n",
       "\t<tr><td>49      </td><td>16.78330</td><td>26      </td><td>1814    </td><td>RW/LW   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " points & timeOnIce & penalty\\_mins & shifts & position\\\\\n",
       "\\hline\n",
       "\t  0       &  8.56667 &  0       &   12     & LW      \\\\\n",
       "\t 21       & 16.65000 & 50       & 1397     & LW/RW   \\\\\n",
       "\t  2       & 12.33330 &  4       &  256     & LW      \\\\\n",
       "\t  5       & 10.23330 & 16       &  431     & C       \\\\\n",
       "\t  3       & 12.78330 &  2       &  117     & LW      \\\\\n",
       "\t 49       & 16.78330 & 26       & 1814     & RW/LW   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "points | timeOnIce | penalty_mins | shifts | position | \n",
       "|---|---|---|---|---|---|\n",
       "|  0       |  8.56667 |  0       |   12     | LW       | \n",
       "| 21       | 16.65000 | 50       | 1397     | LW/RW    | \n",
       "|  2       | 12.33330 |  4       |  256     | LW       | \n",
       "|  5       | 10.23330 | 16       |  431     | C        | \n",
       "|  3       | 12.78330 |  2       |  117     | LW       | \n",
       "| 49       | 16.78330 | 26       | 1814     | RW/LW    | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  points timeOnIce penalty_mins shifts position\n",
       "1  0      8.56667   0             12   LW      \n",
       "2 21     16.65000  50           1397   LW/RW   \n",
       "3  2     12.33330   4            256   LW      \n",
       "4  5     10.23330  16            431   C       \n",
       "5  3     12.78330   2            117   LW      \n",
       "6 49     16.78330  26           1814   RW/LW   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset <- cbind(points, timeOnIce, penalty_mins, shifts)\n",
    "dataset <- as.data.frame(dataset)\n",
    "dataset$position <- as.factor(position)\n",
    "head(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allrighty, now that looks much better than before. No unnecessary columns considering this simple approach. Next I'm going to refactor the position column/feature so that outputs are simply forward and defenseman:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "      C     C/D    C/LW  C/LW/C C/LW/RW    C/RW C/RW/LW       D    D/LW    D/RW \n",
       "    144       1      56       1       9      42       7     296       1       2 \n",
       "     LW    LW/C LW/C/RW   LW/RW LW/RW/C      RW    RW/C RW/C/LW   RW/LW RW/LW/C \n",
       "     79      47      10      34       5      91      23       5      31       4 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1 \n",
       "299 589 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(dataset$position)\n",
    "dataset$position <- as.character(dataset$position)\n",
    "dataset$position[grep(\"^D\",dataset$position)] <- \"Defenseman\"\n",
    "dataset$position[grep(\"\\\\C|\\\\LW|\\\\RW\",dataset$position)] <- \"Forward\"\n",
    "\n",
    "dataset$position <- as.factor(dataset$position)\n",
    "dataset$position <- as.numeric(dataset$position)\n",
    "dataset <- dataset %>%\n",
    "  mutate(position = position - 1)\n",
    "table(dataset$position) #0 = defenseman, 1 = forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above I created frequency tables for different positions in this dataset. Here we can see that many players are versatile so that they can play different positions. Total number of defensemen is 299 and total number of forwards is 589."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I intended to use missmap function that is part of the Amelia package in order to visualize if there are any missing values, but for some reason I can't get it to work in this notebook. But instead I will just use simple base-R command to find out if there are any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum(is.na(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next phase is to build our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for you to recreate my results, I'm going to set seed so that your and mine outputs should match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to split data into training and test set. I will use 75% of the data as training set and 25% as the test set. We are going to create model using training set and after that we test our prediction with test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = sample.split(dataset$position, SplitRatio = 0.75)\n",
    "training_set = subset(dataset, split == TRUE)\n",
    "test_set = subset(dataset, split == FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's scale our numeric values so that different scales don't mess up our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set[-5] = scale(training_set[-5])\n",
    "test_set[-5] = scale(test_set[-5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we get to create our Logistic Regression model. I'm going to use all our dataset columns (1 to 5) and I will create model using training_set. I will also print out summary of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = position ~ ., family = binomial, data = training_set)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-3.9216  -0.1941   0.1663   0.4313   2.3847  \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)    1.3063     0.1556   8.396   <2e-16 ***\n",
       "points         3.7335     0.4218   8.852   <2e-16 ***\n",
       "timeOnIce     -3.6117     0.3075 -11.745   <2e-16 ***\n",
       "penalty_mins  -0.1545     0.1950  -0.792    0.428    \n",
       "shifts        -0.5245     0.3361  -1.560    0.119    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 850.58  on 665  degrees of freedom\n",
       "Residual deviance: 355.33  on 661  degrees of freedom\n",
       "AIC: 365.33\n",
       "\n",
       "Number of Fisher Scoring iterations: 6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = glm(formula = position ~ .,\n",
    "                 family = binomial,\n",
    "                 data = training_set)\n",
    "\n",
    "summary(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are able to see that not our features/columns were relevant to this model. Focus on the last column showing those p-values. Looks like that penalty_mins and shifts are useless features in order to classify player to forwards/defenseman. Threshold for statistical significance is 0.05 and those two last features are far from it. So I'm going to remove those two features in order to improve our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>points</th><th scope=col>timeOnIce</th><th scope=col>position</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 0      </td><td> 8.56667</td><td>1       </td></tr>\n",
       "\t<tr><td>21      </td><td>16.65000</td><td>1       </td></tr>\n",
       "\t<tr><td> 2      </td><td>12.33330</td><td>1       </td></tr>\n",
       "\t<tr><td> 5      </td><td>10.23330</td><td>1       </td></tr>\n",
       "\t<tr><td> 3      </td><td>12.78330</td><td>1       </td></tr>\n",
       "\t<tr><td>49      </td><td>16.78330</td><td>1       </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " points & timeOnIce & position\\\\\n",
       "\\hline\n",
       "\t  0       &  8.56667 & 1       \\\\\n",
       "\t 21       & 16.65000 & 1       \\\\\n",
       "\t  2       & 12.33330 & 1       \\\\\n",
       "\t  5       & 10.23330 & 1       \\\\\n",
       "\t  3       & 12.78330 & 1       \\\\\n",
       "\t 49       & 16.78330 & 1       \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "points | timeOnIce | position | \n",
       "|---|---|---|---|---|---|\n",
       "|  0       |  8.56667 | 1        | \n",
       "| 21       | 16.65000 | 1        | \n",
       "|  2       | 12.33330 | 1        | \n",
       "|  5       | 10.23330 | 1        | \n",
       "|  3       | 12.78330 | 1        | \n",
       "| 49       | 16.78330 | 1        | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  points timeOnIce position\n",
       "1  0      8.56667  1       \n",
       "2 21     16.65000  1       \n",
       "3  2     12.33330  1       \n",
       "4  5     10.23330  1       \n",
       "5  3     12.78330  1       \n",
       "6 49     16.78330  1       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset <- subset(dataset, select = -c(penalty_mins, shifts))\n",
    "head(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do again the train/test split and create the model like before, but this time with only three features. Take notice that when I'm scaling training and test sets, I'm using [,3] instead of [,5]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = position ~ ., family = binomial, data = training_set)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-3.1802  -0.1683   0.1510   0.3664   2.7471  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)   1.3368     0.1612   8.294   <2e-16 ***\n",
       "points        3.5314     0.3064  11.525   <2e-16 ***\n",
       "timeOnIce    -4.0999     0.3255 -12.594   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 850.58  on 665  degrees of freedom\n",
       "Residual deviance: 328.94  on 663  degrees of freedom\n",
       "AIC: 334.94\n",
       "\n",
       "Number of Fisher Scoring iterations: 6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split = sample.split(dataset$position, SplitRatio = 0.75)\n",
    "training_set = subset(dataset, split == TRUE)\n",
    "test_set = subset(dataset, split == FALSE)\n",
    "\n",
    "training_set[-3] = scale(training_set[-3])\n",
    "test_set[-3] = scale(test_set[-3])\n",
    "\n",
    "classifier = glm(formula = position ~ .,\n",
    "                 family = binomial,\n",
    "                 data = training_set)\n",
    "\n",
    "summary(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get to predict classes to player using our test set as new data (of course without position labels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob_pred = predict(classifier, type = 'response', newdata = test_set[-3])\n",
    "y_pred = ifelse(prob_pred > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous cell, if the probability is more than 50% we assign that data point to forward and if it is less than 50% we assign it to defenseman. Next we create a Confusion Matrix to see quickly how our model works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      y_pred\n",
       "y_true   0   1\n",
       "     0  61  14\n",
       "     1   8 139"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrix(y_pred, test_set[,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that our model manages to assign defenseman as defenseman 61 times and it missclassifies it 14 times. Our model assigns forwards to right position 139 times and missclassifies player as forward 8 times. We can also create different metrics to see how well our model works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.900900900900901"
      ],
      "text/latex": [
       "0.900900900900901"
      ],
      "text/markdown": [
       "0.900900900900901"
      ],
      "text/plain": [
       "[1] 0.9009009"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.884057971014493"
      ],
      "text/latex": [
       "0.884057971014493"
      ],
      "text/markdown": [
       "0.884057971014493"
      ],
      "text/plain": [
       "[1] 0.884058"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.847222222222222"
      ],
      "text/latex": [
       "0.847222222222222"
      ],
      "text/markdown": [
       "0.847222222222222"
      ],
      "text/plain": [
       "[1] 0.8472222"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Accuracy(y_pred, test_set[,3])\n",
    "Recall(y_pred, test_set[,3])\n",
    "F1_Score(y_pred, test_set[,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case our model manages to predict right position to players about 9 times out of 10. Pretty good with such a simple model, right! There are also many ways to improve our model, but this is the short demonstration how Logistic Regression works with R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thanks for reading and enjoy coding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
